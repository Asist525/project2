# -*- coding: utf-8 -*-
"""
Batch í•™ìŠµ + ì˜ˆì¸¡ + ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ (Refactored)
- ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ (Prev_Close)
- ì˜¨ë¼ì¸ ëŸ¬ë‹ ì•ˆì „ì„± ê°•í™” (alpha ê°±ì‹  ë°©ì‹ ìˆ˜ì •)
- ì§€í‘œë³„ ë³´ìƒ ê°œì„  + bulk DB ì €ì¥
- ê°€ë…ì„±Â·í…ŒìŠ¤íŠ¸ ì¬í˜„ì„±Â·I/O ìµœì í™”
"""


# mape ì£¼ë¡œí•˜ëŠ” ë‹¨ê¸° ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸
# ë‹¨ê¸°ë¡œ ì‚¬ìš©í•  ê²½ìš° ì˜ˆì¸¡ì„ 21ì¼ì´ ì•„ë‹Œ 7ì¼ ë¯¸ë§Œìœ¼ë¡œ í•´ì•¼ ì˜ë¯¸ìˆëŠ” ë°ì´í„°ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ


from __future__ import annotations

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os, sys, time, logging
from datetime import timedelta
from dataclasses import dataclass
from typing import Iterable, List, Tuple, Sequence

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import numpy as np
import pandas as pd
from pandas.tseries.offsets import CustomBusinessDay
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tabulate import tabulate

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Django ORM bootstrap  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, PROJECT_DIR)
import django
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "backend.settings")
django.setup()
from ai.models import AI_REWARD

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ë‚´ë¶€ ëª¨ë“ˆ  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from nomalization import (
    walk_forward_batches,
    mini_batch_normalization,
    load_model, save_model,
    load_scaler, save_scaler,
    load_or_init_scaler,
    add_sma_features
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ìƒìˆ˜Â·ì „ì—­  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOGGER = logging.getLogger(__name__)
LOGGER.setLevel(logging.INFO)

np.random.seed(42)  # ì¬í˜„ì„± í™•ë³´ (ìš´ì˜ ì‹œ ì‚­ì œ)

EPS                     = 1e-8
ALPHA_MIN               = 1e-8
ALPHA_RESET             = 1e-4
DECAY_K                 = 0.5
DEFAULT_REWARD_WEIGHT   = (0.4, 0.2, 0.2, 0.2)   # MAPEÂ·MAEÂ·RMSEÂ·R2
EXTRA_SMA = [f"SMA_{p}" for p in (5, 20, 60)]
FIT_COLS   = ["Open", "High", "Low", "Volume", "Prev_Close"] + EXTRA_SMA
TARGET_COL              = "Close"
KR_US_BDAY              = CustomBusinessDay(calendar="KRX")  # í•„ìš” ì‹œ KRXÂ·NYSE ë³‘í•©

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ë³´ìƒÂ·Î± í—¬í¼  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _composite_reward(
    mape: float, mae: float, rmse: float, r2: float,
    w: Tuple[float, float, float, float] = DEFAULT_REWARD_WEIGHT,
) -> float:
    """MAPEÂ·MAEÂ·RMSEÂ·RÂ² â†’ 0~1 ìŠ¤ì¼€ì¼ ë³´ìƒ í›„ ê°€ì¤‘ í‰ê· """
    f_error = lambda x: 1.0 / (1.0 + x)           # ì‘ì„ìˆ˜ë¡ â†‘
    f_r2    = lambda x: 1.0 / (1.0 + np.exp(-5 * x))  # S-shaped, x âˆˆ (âˆ’âˆ,1]
    reward  = (
        w[0] * f_error(mape) +
        w[1] * f_error(mae)  +
        w[2] * f_error(rmse) +
        w[3] * f_r2(r2)
    ) / sum(w)
    return reward  # 0~1 ì‚¬ì´


def _update_alpha(cur_alpha: float, reward: float) -> float:
    """exp ê°ì‡ ë¡œ ê·œì œ ê°•ë„ ì—…ë°ì´íŠ¸, ALPHA_MIN ì´í•˜ë¡œëŠ” ì˜ë¼ëƒ„"""
    new_alpha = cur_alpha * np.exp(-DECAY_K * reward)
    return max(new_alpha, ALPHA_MIN)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ê²°ê³¼ êµ¬ì¡°ì²´  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass
class BatchResult:
    train_period: Tuple[str, str]
    pred_period: Tuple[str, str]
    mape: float
    mae: float
    rmse: float
    r2: float
    reward: float
    y_true: np.ndarray
    y_pred: np.ndarray

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  í•µì‹¬ í•¨ìˆ˜  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def partial_fit_batches(
    batches: Iterable[Tuple[pd.DataFrame, pd.DataFrame]],
    model: SGDRegressor | None = None,
    scaler: MinMaxScaler | None = None,
    reward_weights: Tuple[float, float, float, float] = DEFAULT_REWARD_WEIGHT,
    verbose: bool = True,
) -> Tuple[SGDRegressor, MinMaxScaler, List[BatchResult]]:
    """walk-forward ë°°ì¹˜ í•™ìŠµ + ë‹¤ì¤‘ ìŠ¤í… ì˜ˆì¸¡"""

    # â”€â”€ ëª¨ë¸Â·ìŠ¤ì¼€ì¼ëŸ¬ ì¤€ë¹„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if model is None:
        model = SGDRegressor(
            loss="huber",
            epsilon=1.35,
            random_state=42,
            penalty="l2",
            alpha=ALPHA_RESET,
            learning_rate="invscaling",
            eta0=0.01,
            power_t=0.25,
            fit_intercept=True,
        )
    if scaler is None:
        scaler = MinMaxScaler()

    results: List[BatchResult] = []

    # â”€â”€ ë°°ì¹˜ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for train_b, pred_b in batches:
        if train_b.empty or pred_b.empty:
            continue
        if "SMA_5" not in train_b.columns:
            train_b = add_sma_features(train_b, periods=(5,20,60))
            pred_b  = add_sma_features(pred_b,  periods=(5,20,60))

        # Prev_Close (ëˆ„ìˆ˜ ë°©ì§€) + ì²« í–‰ ì œê±°
        train_b = train_b.copy()
        train_b["Prev_Close"] = train_b[TARGET_COL].shift(1)
        train_b.dropna(subset=["Prev_Close"], inplace=True)  # ì²« í–‰ ì œê±°

        # ìŠ¤ì¼€ì¼ëŸ¬ ì ì§„ í•™ìŠµ & ë³€í™˜
        scaler.partial_fit(train_b[FIT_COLS])
        X_train = pd.DataFrame(
            scaler.transform(train_b[FIT_COLS]),
            columns=FIT_COLS,
            index=train_b.index,
        )
        y_train = train_b[TARGET_COL].values

        model.partial_fit(X_train, y_train)

        # â”€â”€ ë‹¤ì¤‘ ìŠ¤í… ì˜ˆì¸¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        last_row = X_train.iloc[-1].copy()
        idx_prev = FIT_COLS.index("Prev_Close")

        y_pred: List[float] = []
        for _ in range(len(pred_b)):
            next_val = float(model.predict(pd.DataFrame([last_row], columns=FIT_COLS))[0])
            y_pred.append(next_val)

            # Prev_Close ê°±ì‹ 
            last_row.iloc[idx_prev] = next_val

            # íƒìƒ‰ ë…¸ì´ì¦ˆ (Âµ=0, Ïƒ=0.01) â€“ Open~Volume í”¼ì²˜ì—ë§Œ
            noise = np.random.normal(0.0, 0.01, size=idx_prev)
            last_row.iloc[:idx_prev] += noise

        # â”€â”€ ì§€í‘œ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        y_true = pred_b[TARGET_COL].astype(float).values
        y_pred = np.array(y_pred)

        # NaN í•„í„°ë§
        valid_mask = ~np.isnan(y_true) & ~np.isnan(y_pred)
        if not valid_mask.any():
            LOGGER.warning("âŒ No valid samples (all NaN) â†’ Batch skipped")
            continue
        y_true = y_true[valid_mask]
        y_pred = y_pred[valid_mask]

        mae  = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mape = np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + EPS))) * 100.0
        if mape > 100:
            continue
        r2   = r2_score(y_true, y_pred)

        reward = _composite_reward(mape, mae, rmse, r2, reward_weights)

        # alpha ê°±ì‹  (ë‹¤ìŒ ë°°ì¹˜ë¶€í„° ë°˜ì˜)
        new_alpha = _update_alpha(model.alpha if np.isfinite(model.alpha) else ALPHA_RESET, reward)
        model.set_params(alpha=new_alpha)

        # â”€â”€ ê²°ê³¼ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        results.append(
            BatchResult(
                train_period=(
                    train_b["Date"].min().strftime("%Y-%m-%d"),
                    train_b["Date"].max().strftime("%Y-%m-%d"),
                ),
                pred_period=(
                    pred_b["Date"].min().strftime("%Y-%m-%d"),
                    pred_b["Date"].max().strftime("%Y-%m-%d"),
                ),
                mape=mape,
                mae=mae,
                rmse=rmse,
                r2=r2,
                reward=reward,
                y_true=y_true,
                y_pred=np.array(y_pred),
            )
        )

        # â”€â”€ ë¡œê·¸ & ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if verbose:
            table = [
                ["MAPE (%)", f"{mape:.0f}"],
                ["MAE",      f"{mae:.4f}"],
                ["RMSE",     f"{rmse:.4f}"],
                ["R2",       f"{r2:.4f}"],
                ["Reward",   f"{reward:.4f}"],
                ["Î±",        f"{new_alpha:.8f}"],
            ]
            print(tabulate(table, headers=["Metric", "Value"], tablefmt="github"))
        
        

    return model, scaler, results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  DB ì €ì¥  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def save_results_bulk(results: List[BatchResult]):
    objs = []
    for r in results:
        if any(np.isnan([r.mape, r.mae, r.rmse, r.r2, r.reward])):
            LOGGER.warning("Skip save: NaN found in metrics")
            continue
        objs.append(
            AI_REWARD(
                MAPE   = min(r.mape,   9999.999999),
                MAE    = min(r.mae,    9999.999999),
                RMSE   = min(r.rmse,   9999.999999),
                R2     = max(min(r.r2, 9999.999999), -9999.999999),
                REWARD = min(r.reward, 9999.999999),
            )
        )
    if objs:
        AI_REWARD.objects.bulk_create(objs)
        LOGGER.info(f"âœ… Saved {len(objs)} rows to AI_REWARD")
from pathlib import Path
from pathlib import Path
import pandas as pd

MODEL_PATH  = Path("models/price_model.pkl")
SCALER_PATH = Path("models/price_scaler.pkl")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  debug switch  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEBUG_FIRST_BATCH = False         # â† í•„ìš”í•  ë•Œë§Œ True

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ë©”ì¸  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    ticker = "QQQ"
    while True:
        # 1) ìµœì‹  ë°°ì¹˜
        batches = list(walk_forward_batches(mini_batch_normalization(ticker)))

        # ğŸ” ì²« ë°°ì¹˜ ë””ë²„ê·¸ ----------------------------------
        if DEBUG_FIRST_BATCH and batches:
            train_b, pred_b = batches[0]

            print("\nğŸŸ¡  [ë””ë²„ê·¸] ì²« batch-train head()")
            print(train_b.head())
            print("\nğŸŸ¡  [ë””ë²„ê·¸] ì²« batch-pred head()")
            print(pred_b.head())

            sma_cols = [c for c in train_b.columns if c.startswith("SMA_")]
            print("\nğŸŸ¢  í¬í•¨ëœ SMA ì»¬ëŸ¼:", sma_cols, "\n")
            input("â–¶ ì—”í„°ë¥¼ ëˆ„ë¥´ë©´ í•™ìŠµì„ ê³„ì†í•©ë‹ˆë‹¤â€¦")

        # 2) ëª¨ë¸Â·ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ (ì—†ìœ¼ë©´ ìƒˆë¡œ)
        model  = load_model(MODEL_PATH) if MODEL_PATH.exists() else SGDRegressor()
        scaler = load_or_init_scaler(SCALER_PATH, FIT_COLS)

        # 3) í•™ìŠµ
        model, scaler, results = partial_fit_batches(
            batches, model=model, scaler=scaler, verbose=True
        )

        # 4) ì €ì¥
        save_model(model, MODEL_PATH)
        save_scaler(scaler, SCALER_PATH)
        save_results_bulk(results)

        print("\nâœ…  ëª¨ë¸Â·ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ\n")



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì—”íŠ¸ë¦¬  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("Interrupted â€“ shutting down cleanly")
